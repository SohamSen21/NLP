{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTMrw56JsheDcR57BJRPDU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SohamSen21/BCS_task/blob/main/Sherlock_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TEtdygfODdJ"
      },
      "outputs": [],
      "source": [
        "# Import tensorflow and other necessary libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('sherlock.txt', 'https://assets.datacamp.com/production/repositories/3937/datasets/213ca262bf6af12428d42842848464565f3d5504/sherlock.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzQ1o1AaP0S8",
        "outputId": "a057d001-24da-412a-aa65-e5d74feb6ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://assets.datacamp.com/production/repositories/3937/datasets/213ca262bf6af12428d42842848464565f3d5504/sherlock.txt\n",
            "6488666/6488666 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU7UOGNmBHPn",
        "outputId": "c2f5938b-65d9-4478-9390-b6d666d85dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 6488666 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 10000 characters in text\n",
        "print(text[:10000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evLznmk0BSsD",
        "outputId": "674b3a1a-f583-44bc-ca75-bb4398230866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Project Gutenberg EBook of The Adventures of Sherlock Holmes\n",
            "by Sir Arthur Conan Doyle\n",
            "(#15 in our series by Sir Arthur Conan Doyle)\n",
            "\n",
            "Copyright laws are changing all over the world. Be sure to check the\n",
            "copyright laws for your country before downloading or redistributing\n",
            "this or any other Project Gutenberg eBook.\n",
            "\n",
            "This header should be the first thing seen when viewing this Project\n",
            "Gutenberg file.  Please do not remove it.  Do not change or edit the\n",
            "header without written permission.\n",
            "\n",
            "Please read the \"legal small print,\" and other information about the\n",
            "eBook and Project Gutenberg at the bottom of this file.  Included is\n",
            "important information about your specific rights and restrictions in\n",
            "how the file may be used.  You can also find out about how to make a\n",
            "donation to Project Gutenberg, and how to get involved.\n",
            "\n",
            "\n",
            "**Welcome To The World of Free Plain Vanilla Electronic Texts**\n",
            "\n",
            "**eBooks Readable By Both Humans and By Computers, Since 1971**\n",
            "\n",
            "*****These eBooks Were Prepared By Thousands of Volunteers!*****\n",
            "\n",
            "\n",
            "Title: The Adventures of Sherlock Holmes\n",
            "\n",
            "Author: Sir Arthur Conan Doyle\n",
            "\n",
            "Release Date: March, 1999  [EBook #1661]\n",
            "[Most recently updated: November 29, 2002]\n",
            "\n",
            "Edition: 12\n",
            "\n",
            "Language: English\n",
            "\n",
            "Character set encoding: ASCII\n",
            "\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK, THE ADVENTURES OF SHERLOCK HOLMES ***\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(Additional editing by Jose Menendez)\n",
            "\n",
            "\n",
            "\n",
            "THE ADVENTURES OF\n",
            "SHERLOCK HOLMES\n",
            "\n",
            "BY\n",
            "\n",
            "SIR ARTHUR CONAN DOYLE\n",
            "\n",
            "CONTENTS\n",
            "\n",
            "I.\tA Scandal in Bohemia\n",
            "II.\tThe Red-Headed League\n",
            "III.\tA Case of Identity\n",
            "IV.\tThe Boscombe Valley Mystery\n",
            "V.\tThe Five Orange Pips\n",
            "VI.\tThe Man with the Twisted Lip\n",
            "VII.\tThe Adventure of the Blue Carbuncle\n",
            "VIII.\tThe Adventure of the Speckled Band\n",
            "IX.\tThe Adventure of the Engineer's Thumb\n",
            "X.\tThe Adventure of the Noble Bachelor\n",
            "XI.\tThe Adventure of the Beryl Coronet\n",
            "XII.\tThe Adventure of the Copper Beeches\n",
            "\n",
            "\n",
            "ADVENTURE  I.  A SCANDAL IN BOHEMIA\n",
            "\n",
            "I.\n",
            "\n",
            "\n",
            "To Sherlock Holmes she is always the woman. I have seldom heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. He never spoke of the softer passions, save with a gibe and a sneer. They were admirable things for the observer--excellent for drawing the veil from men's motives and actions. But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.\n",
            "\n",
            "I had seen little of Holmes lately. My marriage had drifted us away from each other. My own complete happiness, and the home-centred interests which rise up around the man who first finds himself master of his own establishment, were sufficient to absorb all my attention, while Holmes, who loathed every form of society with his whole Bohemian soul, remained in our lodgings in Baker Street, buried among his old books, and alternating from week to week between cocaine and ambition, the drowsiness of the drug, and the fierce energy of his own keen nature. He was still, as ever, deeply attracted by the study of crime, and occupied his immense faculties and extraordinary powers of observation in following out those clues, and clearing up those mysteries which had been abandoned as hopeless by the official police. From time to time I heard some vague account of his doings: of his summons to Odessa in the case of the Trepoff murder, of his clearing up of the singular tragedy of the Atkinson brothers at Trincomalee, and finally of the mission which he had accomplished so delicately and successfully for the reigning family of Holland. Beyond these signs of his activity, however, which I merely shared with all the readers of the daily press, I knew little of my former friend and companion.\n",
            "\n",
            "One night--it was on the twentieth of March, 1888--I was returning from a journey to a patient (for I had now returned to civil practice), when my way led me through Baker Street. As I passed the well-remembered door, which must always be associated in my mind with my wooing, and with the dark incidents of the Study in Scarlet, I was seized with a keen desire to see Holmes again, and to know how he was employing his extraordinary powers. His rooms were brilliantly lit, and, even as I looked up, I saw his tall, spare figure pass twice in a dark silhouette against the blind. He was pacing the room swiftly, eagerly, with his head sunk upon his chest and his hands clasped behind him. To me, who knew his every mood and habit, his attitude and manner told their own story. He was at work again. He had risen out of his drug-created dreams and was hot upon the scent of some new problem. I rang the bell and was shown up to the chamber which had formerly been in part my own.\n",
            "\n",
            "His manner was not effusive. It seldom was; but he was glad, I think, to see me. With hardly a word spoken, but with a kindly eye, he waved me to an armchair, threw across his case of cigars, and indicated a spirit case and a gasogene in the corner. Then he stood before the fire and looked me over in his singular introspective fashion.\n",
            "\n",
            "\"Wedlock suits you,\" he remarked. \"I think, Watson, that you have put on seven and a half pounds since I saw you.\"\n",
            "\n",
            "\"Seven!\" I answered.\n",
            "\n",
            "\"Indeed, I should have thought a little more. Just a trifle more, I fancy, Watson. And in practice again, I observe. You did not tell me that you intended to go into harness.\"\n",
            "\n",
            "\"Then, how do you know?\"\n",
            "\n",
            "\"I see it, I deduce it. How do I know that you have been getting yourself very wet lately, and that you have a most clumsy and careless servant girl?\"\n",
            "\n",
            "\"My dear Holmes,\" said I, \"this is too much. You would certainly have been burned, had you lived a few centuries ago. It is true that I had a country walk on Thursday and came home in a dreadful mess, but as I have changed my clothes I can't imagine how you deduce it. As to Mary Jane, she is incorrigible, and my wife has given her notice, but there, again, I fail to see how you work it out.\"\n",
            "\n",
            "He chuckled to himself and rubbed his long, nervous hands together.\n",
            "\n",
            "\"It is simplicity itself,\" said he; \"my eyes tell me that on the inside of your left shoe, just where the firelight strikes it, the leather is scored by six almost parallel cuts. Obviously they have been caused by someone who has very carelessly scraped round the edges of the sole in order to remove crusted mud from it. Hence, you see, my double deduction that you had been out in vile weather, and that you had a particularly malignant boot-slitting specimen of the London slavey. As to your practice, if a gentleman walks into my rooms smelling of iodoform, with a black mark of nitrate of silver upon his right forefinger, and a bulge on the right side of his top-hat to show where he has secreted his stethoscope, I must be dull, indeed, if I do not pronounce him to be an active member of the medical profession.\"\n",
            "\n",
            "I could not help laughing at the ease with which he explained his process of deduction. \"When I hear you give your reasons,\" I remarked, \"the thing always appears to me to be so ridiculously simple that I could easily do it myself, though at each successive instance of your reasoning I am baffled until you explain your process. And yet I believe that my eyes are as good as yours.\"\n",
            "\n",
            "\"Quite so,\" he answered, lighting a cigarette, and throwing himself down into an armchair. \"You see, but you do not observe. The distinction is clear. For example, you have frequently seen the steps which lead up from the hall to this room.\"\n",
            "\n",
            "\"Frequently.\"\n",
            "\n",
            "\"How often?\"\n",
            "\n",
            "\"Well, some hundreds of times.\"\n",
            "\n",
            "\"Then how many are there?\"\n",
            "\n",
            "\"How many? I don't know.\"\n",
            "\n",
            "\"Quite so! You have not observed. And yet you have seen. That is just my point. Now, I know that there are seventeen steps, because I have both seen and observed. By the way, since you are interested in these little problems, and since you are good enough to chronicle one or two of my trifling experiences, you may be interested in this.\" He threw over a sheet of thick, pink-tinted notepaper which had been lying open upon the table. \"It came by the last post,\" said he. \"Read it aloud.\"\n",
            "\n",
            "The note was undated, and without either signature or address.\n",
            "\n",
            "\"There will call upon you to-night, at a quarter to eight o'clock,\" it said, \"a gentleman who desires to consult you upon a matter of the very deepest moment. Your recent services to one of the royal houses of Europe have shown that you are one who may safely be trusted with matters which are of an importance which can hardly be exaggerated. This account of you we have from all quarters received. Be in your chamber then at that hour, and do not take it amiss if your visitor wear a mask.\"\n",
            "\n",
            "\"This is indeed a mystery,\" I remarked. \"What do you imagine that it means?\"\n",
            "\n",
            "\"I have no data yet. It is a capital mistake to theorise before one has data. Insensibly one begins to twist facts to suit theories, instead of theories to suit facts. But the note itself. What do you deduce from it?\"\n",
            "\n",
            "I carefully examined the writing, and the paper upon which it was written.\n",
            "\n",
            "\"The man who wrote it was presumably well to do,\" I remarked, endeavouring to imitate my companion's processes. \"Such paper could not be bought under half a crown a packet. It is peculiarly strong and stiff.\"\n",
            "\n",
            "\"Peculiar--that is the very word,\" said Holmes. \"It is not an English paper at all. Hold it up to the light.\"\n",
            "\n",
            "I did so, and saw a large \"E\" with a small \"g,\" a \"P,\" and a large \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXQyLt6WBjyP",
        "outputId": "12c06646-e788-4901-c95d-ee051ba5ba96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "93 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYUYFCtABoxL",
        "outputId": "10e1e2a4-96e7-4758-c0c0-cf2b0b8c1865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "DVHDIp_TB1wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsuuszvXB51a",
        "outputId": "d4757e7a-deac-4f44-e983-4b2e14b9e041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[66, 67, 68, 69, 70, 71, 72], [89, 90, 91]]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "KHkmngtmB9m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21pGvJaQCBef",
        "outputId": "3984f786-1728-4fff-eef6-2dd6190c2e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go8LW88kCFS9",
        "outputId": "b1d25e95-2770-43c5-8925-aeddb5754002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "D9dPfbaOCJCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDN72ldKCN0M",
        "outputId": "56238c96-68ab-4c35-87d2-fa827e68406d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6488666,), dtype=int64, numpy=array([55, 73, 70, ..., 84, 63,  2])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "slUJVlkWCR-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvggJjBeCVjE",
        "outputId": "424a7b16-12a6-4799-de65-05970d832f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T\n",
            "h\n",
            "e\n",
            " \n",
            "P\n",
            "r\n",
            "o\n",
            "j\n",
            "e\n",
            "c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n"
      ],
      "metadata": {
        "id": "TkywFvnvCdPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAZNvjHNChTP",
        "outputId": "e73c8117-747a-475f-b455-20771457e835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'T' b'h' b'e' b' ' b'P' b'r' b'o' b'j' b'e' b'c' b't' b' ' b'G' b'u'\n",
            " b't' b'e' b'n' b'b' b'e' b'r' b'g' b' ' b'E' b'B' b'o' b'o' b'k' b' '\n",
            " b'o' b'f' b' ' b'T' b'h' b'e' b' ' b'A' b'd' b'v' b'e' b'n' b't' b'u'\n",
            " b'r' b'e' b's' b' ' b'o' b'f' b' ' b'S' b'h' b'e' b'r' b'l' b'o' b'c'\n",
            " b'k' b' ' b'H' b'o' b'l' b'm' b'e' b's' b'\\n' b'b' b'y' b' ' b'S' b'i'\n",
            " b'r' b' ' b'A' b'r' b't' b'h' b'u' b'r' b' ' b'C' b'o' b'n' b'a' b'n'\n",
            " b' ' b'D' b'o' b'y' b'l' b'e' b'\\n' b'(' b'#' b'1' b'5' b' ' b'i' b'n'\n",
            " b' ' b'o' b'u'], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXaNYYrkCltz",
        "outputId": "7f565e31-0b67-49e1-98d8-c18f0970ea66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'The Project Gutenberg EBook of The Adventures of Sherlock Holmes\\nby Sir Arthur Conan Doyle\\n(#15 in ou'\n",
            "b'r series by Sir Arthur Conan Doyle)\\n\\nCopyright laws are changing all over the world. Be sure to check'\n",
            "b' the\\ncopyright laws for your country before downloading or redistributing\\nthis or any other Project G'\n",
            "b'utenberg eBook.\\n\\nThis header should be the first thing seen when viewing this Project\\nGutenberg file.'\n",
            "b'  Please do not remove it.  Do not change or edit the\\nheader without written permission.\\n\\nPlease read'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "hEKqJoQUCqCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKTWRuOiCt1y",
        "outputId": "19ddfd71-cc45-4d53-9e04-85e0a0a006ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "i3To9lEACxQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhQ9rrALC0aS",
        "outputId": "cf5c6052-446a-4d3a-d593-56d053695bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'The Project Gutenberg EBook of The Adventures of Sherlock Holmes\\nby Sir Arthur Conan Doyle\\n(#15 in o'\n",
            "Target: b'he Project Gutenberg EBook of The Adventures of Sherlock Holmes\\nby Sir Arthur Conan Doyle\\n(#15 in ou'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3fujzWFC4-q",
        "outputId": "d0fb9456-dfa6-4e46-e52a-49ec730fd297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "YS2VsEB-C8pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "vQXu0lB2DAJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "cTVIvEnvDENn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFs6q4i7DMxQ",
        "outputId": "df880328-1341-4721-fc48-de61d692cf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 94) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc8fs7fTDUZr",
        "outputId": "8c798c65-e23a-439f-dcc8-4d4be36e1b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  24064     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  96350     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,058,718\n",
            "Trainable params: 4,058,718\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "K67yoI-1DaA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUQimVjODbrh",
        "outputId": "ceadb40b-02de-405c-e0ce-0fc4dc77935e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([28, 30, 51, 59, 64, 56, 72,  2, 12, 19, 72, 49, 93, 64, 47, 68, 27,\n",
              "       71, 40, 28, 13, 49, 38, 82,  2, 51, 92, 83, 70, 26, 64, 76, 45, 64,\n",
              "       31,  0, 21, 74,  5, 35, 41, 35, 60, 18, 81,  4, 20, 44, 65, 10, 69,\n",
              "       38, 63, 92, 38, 28, 75, 73, 31, 17,  1, 58, 70, 43, 72, 43, 59, 80,\n",
              "       60, 31, 41, 18,  6, 89, 51, 34, 72, 20, 80, 73,  3, 52, 32, 31, 43,\n",
              "       72, 42, 25,  8, 89,  6, 43, 72, 12, 17,  4, 72, 12, 58, 47])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPT-dbbKDkwj",
        "outputId": "aacf1dd9-7b9f-4b63-f35a-a023fba31f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'd London street. Looking over his shoulder, I saw that on the pavement opposite there stood a large '\n",
            "\n",
            "Next Char Predictions:\n",
            " b'9;PX^Ug\\n)0gN~^Lc8fE9*NCq\\nP|re7^kJ^<[UNK]2i\"@F@Y/p!1I_\\'dC]|C9jh<.\\tWeHgHXoY<F/#xP?g1oh Q=<HgG6%x#Hg).!g)WL'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "YYqVA8u5DuT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_dr6d1vDzHQ",
        "outputId": "e07f0896-3ac0-47da-bdb5-0ab966ca56c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 94)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.543341, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Pg7MaPMD5QM",
        "outputId": "eb52122a-4c86-4197-c8ff-7688b69eafa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "94.00436"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "UFUJl5rTD-R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "F4OqDGWYEC21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "7cR0zkTBEIcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "qmAASBpoER4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ0DhXMuEYKT",
        "outputId": "c6f1ed9e-bf56-4684-9978-2bf84d6ae2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1003/1003 [==============================] - 64s 58ms/step - loss: 1.8468\n",
            "Epoch 2/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.3185\n",
            "Epoch 3/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.2218\n",
            "Epoch 4/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.1716\n",
            "Epoch 5/20\n",
            "1003/1003 [==============================] - 56s 54ms/step - loss: 1.1367\n",
            "Epoch 6/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.1099\n",
            "Epoch 7/20\n",
            "1003/1003 [==============================] - 57s 54ms/step - loss: 1.0884\n",
            "Epoch 8/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.0705\n",
            "Epoch 9/20\n",
            "1003/1003 [==============================] - 56s 54ms/step - loss: 1.0563\n",
            "Epoch 10/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.0447\n",
            "Epoch 11/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.0361\n",
            "Epoch 12/20\n",
            "1003/1003 [==============================] - 56s 54ms/step - loss: 1.0293\n",
            "Epoch 13/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.0245\n",
            "Epoch 14/20\n",
            "1003/1003 [==============================] - 56s 54ms/step - loss: 1.0216\n",
            "Epoch 15/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.0198\n",
            "Epoch 16/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.0199\n",
            "Epoch 17/20\n",
            "1003/1003 [==============================] - 56s 54ms/step - loss: 1.0201\n",
            "Epoch 18/20\n",
            "1003/1003 [==============================] - 56s 54ms/step - loss: 1.0234\n",
            "Epoch 19/20\n",
            "1003/1003 [==============================] - 57s 54ms/step - loss: 1.0269\n",
            "Epoch 20/20\n",
            "1003/1003 [==============================] - 57s 55ms/step - loss: 1.0303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "XDWPhUPSKcSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "bM37s3oZKjZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Watson'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XMwTx8YKpSl",
        "outputId": "c21f012b-49c3-4580-b754-2ee366ba73d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Watson's attempt to waist and the rest.\n",
            "\n",
            "After the result of a mucous swallowy contraction of the first man\n",
            "the entrance to questions and peasants and lifes of the band, the\n",
            "so-called up the mouth, they were told as her days. But he heard the\n",
            "officer into the road on his head.\n",
            "\n",
            "\"And here has no conception on their will. Yesterday Can\n",
            "nerve me at the end of us \"goodnesses \"for me to see him.\"\n",
            "\n",
            "\"Call Him!\" Napoleon replied to the pale eyebrows girly\n",
            "hungry to the cart was of this to the people again appointed.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CHAPTER XV\n",
            "\n",
            "\n",
            "Wither the presents chyless himself against thom were all muttered\n",
            "just as if possible, indorsed some of good service and lack on and love him back\n",
            "in which he had noticed that was had ridden before the ruge till the\n",
            "present streets about in Mass.\n",
            "\n",
            "On his cagn, following him for supposed to feed, the\n",
            "evening. So now this is what the clouds even independent of it\n",
            "askanal, a bettal light between the difficulties of\n",
            "disgusting at Kalukhovo in a sense of knit, presented its \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.5894761085510254\n"
          ]
        }
      ]
    }
  ]
}